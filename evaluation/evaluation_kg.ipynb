{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from db.datasets import datasets\n",
    "from config import system_configs\n",
    "import json, os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/KPDetection.json', \"r\") as f:\n",
    "    configs = json.load(f)\n",
    "    \n",
    "split = 'valchart'\n",
    "\n",
    "configs[\"system\"][\"data_dir\"] = \"extracted_data/chart/\"\n",
    "configs[\"system\"][\"cache_dir\"] = \"extracted_data/chart/cache/\"\n",
    "\n",
    "configs[\"system\"][\"dataset\"] =  \"Chart\"\n",
    "configs[\"system\"][\"snapshot_name\"] = \"PretrainKP\"\n",
    "system_configs.update_config(configs[\"system\"])\n",
    "db = datasets[\"Chart\"](configs[\"db\"], split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pie_center(a, b, c):\n",
    "    a,b,c = np.array(a), np.array(b), np.array(c)\n",
    "    ca = c - a\n",
    "    cb = c - b\n",
    "    # 计算向量 ca 和 cb 之间的角度的余弦值。\n",
    "    cosine_angle = np.dot(ca, cb) / (np.linalg.norm(ca) * np.linalg.norm(cb))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    r_square = (ca**2).sum()\n",
    "   # 判断向量 ca 和 cb 的叉积的符号。这一步用于确定扇形是在向量 ca 和 cb 之间还是在向量 ca 和 cb 之外。 \n",
    "    if ca[0]*cb[1]-ca[1]*cb[0] >= 0:\n",
    "        # 如果叉积大于或等于 0，则返回扇形的几何中心和面积（这里假设扇形是在向量 ca 和 cb 之间）。\n",
    "        return (a[0]+b[0]+c[0])/3., (a[1]+b[1]+c[1])/3., 0.5 * angle * r_square\n",
    "    else:\n",
    "        # 否则，返回扇形外侧的几何中心和面积。\n",
    "        return 2*c[0]-(a[0]+b[0]+c[0])/3., 2*c[1]-(a[1]+b[1]+c[1])/3., np.pi * r_square - 0.5 * angle * r_square\n",
    "\n",
    "def get_grouped_points(gts, preds, chartType):\n",
    "    gt_groups = []\n",
    "    area = 0\n",
    "        \n",
    "    if chartType == 'Bar':\n",
    "        # 遍历所有 ground truth 边界框。\n",
    "        for bbox in gts:\n",
    "            # 计算边界框的面积。\n",
    "            area = np.abs((bbox[2] - bbox[0]) * (bbox[3] - bbox[1])) \n",
    "            # 如果面积为 0，则跳过这个边界框。\n",
    "            if area == 0: continue\n",
    "            # 将非零面积的 ground truth 添加到 gt_groups。\n",
    "            gt_groups.append((bbox[:-1].reshape(-1, 2), area))\n",
    "    elif chartType == 'Pie':\n",
    "        for bbox in gts:\n",
    "            # 处理逻辑与条形图类似，但是使用了 get_pie_center 函数来计算饼图分片的面积。\n",
    "            a, b, c = (bbox[0], bbox[1]), (bbox[2], bbox[3]), (bbox[4], bbox[5])\n",
    "            _, _, area = get_pie_center(a,b,c)        \n",
    "            if area == 0: continue\n",
    "            gt_groups.append((bbox[:-1].reshape(-1, 2), area))\n",
    "    elif chartType == 'Line':\n",
    "        for bbox in gts:\n",
    "            # 遍历 ground truth，并使用特定的计算方式来获取面积。\n",
    "            detection = np.array(bbox)\n",
    "            if len(detection) <= 1: continue\n",
    "            assert len(detection) % 2 == 0\n",
    "            \n",
    "            xs = detection[0:len(detection):2]\n",
    "            ys = detection[1:len(detection):2]\n",
    "            area = (max(max(xs) - min(xs), max(ys) - min(ys)) / len(detection) * 2) ** 2\n",
    "            if area == 0: continue\n",
    "                \n",
    "            gt_groups.append((bbox.reshape(-1, 2), area))   \n",
    "\n",
    "    pred_groups = []\n",
    "    if '1' not in preds[0]: # baseline predictions\n",
    "        if chartType == 'Pie':\n",
    "            for pred in preds:\n",
    "                pred_groups.append(np.array(pred[:-1]))\n",
    "        elif chartType == 'Line':\n",
    "            for pred in preds:\n",
    "                pred_groups.append(np.array(pred))\n",
    "        else:\n",
    "            for pred in preds:\n",
    "                pred_groups.append(np.array(pred).reshape(-1, 2))\n",
    "    else:\n",
    "        for pred in preds[2]:\n",
    "            pred_groups.append(np.array(pred[2:-1]).reshape(-1, 2))\n",
    "    return gt_groups, pred_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 Object Keypoint Similarity（物体关键点相似度）。这是一种常用于评估物体检测和关键点估计任务性能的指标。\n",
    "def OKS(gt_p, pred_p, area):\n",
    "    # 计算了两个二维点（gt_p 为 ground truth 点，pred_p 为预测点）之间的欧氏距离的平方。\n",
    "    d2 = (gt_p[0] - pred_p[0]) ** 2 + (gt_p[1] - pred_p[1]) ** 2\n",
    "    # 一个常数，用于调整距离的权重。这个值可以根据具体应用进行调整。\n",
    "    k2 = 0.1\n",
    "    # 将函数输入的 area 直接赋值给 s2，表示物体或特征的面积。面积越大，对距离的容忍度越高。\n",
    "    s2 = area\n",
    "    #  OKS 的计算公式。函数返回一个介于 0 和 1 之间的值，用于表示 gt_p 和 pred_p 之间的相似度。值越接近 1，表示两点越相似。\n",
    "    return np.exp(d2/(s2 * k2) * (-1))\n",
    "\n",
    "# 计算一组物体关键点（gt_ps 为 ground truth 关键点，pred_ps 为预测关键点）之间的平均 Object Keypoint Similarity（OKS）。\n",
    "def GroupOKS(gt_ps, pred_ps):\n",
    "    # 初始化一个空列表，用于存储每个预测点与所有 ground truth 点之间的最大 OKS。\n",
    "    group_score = []\n",
    "    for pred_p in pred_ps:\n",
    "        # 初始化 max_score 为 0，用于存储当前预测点与所有 ground truth 点之间的最大 OKS。\n",
    "        max_score = 0.\n",
    "        for gt_p in gt_ps[0]:\n",
    "            max_score = max(max_score, OKS(gt_p, pred_p, gt_ps[1]))\n",
    "        group_score.append(max_score)\n",
    "        # 计算 group_score 列表中所有 OKS 的平均值，并返回。\n",
    "    return sum(group_score)/len(group_score)\n",
    "\n",
    "def computePrecision(gt_groups, pred_groups, thres=0.75):\n",
    "    count = 0\n",
    "    for pred_ps in pred_groups:\n",
    "        for gt_ps in gt_groups:\n",
    "            if GroupOKS(gt_ps, pred_ps) > thres:\n",
    "                count += 1\n",
    "                break\n",
    "\n",
    "    return count / len(pred_groups)\n",
    "\n",
    "def computeRecall(gt_groups, pred_groups, thres=0.75):\n",
    "    count = 0\n",
    "    for gt_ps in gt_groups:\n",
    "        for pred_ps in pred_groups:\n",
    "            if GroupOKS(gt_ps, pred_ps) > thres:\n",
    "                count += 1\n",
    "                break\n",
    "\n",
    "    return count / len(gt_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/my_eval/bar/GroupBar50000.json') as f:\n",
    "    prediction = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/my_eval/bar/images/val2019\n",
      "data/my_eval/bar/images/val2019/{}\n",
      "[0 1]\n",
      "data/my_eval/bar\n",
      "data/my_eval/bar/annotations/instancesBar(1031)_val2019.json\n",
      "data/my_eval/cache/chart_val2019.pkl\n"
     ]
    }
   ],
   "source": [
    "print(db._image_dir)\n",
    "print(db._image_file)\n",
    "print(db._db_inds)\n",
    "print(db._coco_dir)\n",
    "print(db._label_file)\n",
    "print(db._cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 46.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# compute 0.75\n",
    "macro_P = []\n",
    "macro_R = []\n",
    "max_iter = db.db_inds.size\n",
    "\n",
    "for i in tqdm(range(max_iter)):\n",
    "\n",
    "    db_ind = db.db_inds[i]\n",
    "    image_file = db.image_file(db_ind)\n",
    "    gts = db.detections(db_ind)\n",
    "    if gts is None or len(gts) == 0: continue\n",
    "    gts = gts[0] if chartType == 'Line' else gts\n",
    "    if len(gts) == 0: continue\n",
    "    preds = prediction[image_file.split('/')[-1]]\n",
    "    if preds is None or len(preds) == 0: continue\n",
    "    if len(preds) == 3 and len(preds[2]) == 0: continue\n",
    "    gt_groups, pred_groups = get_grouped_points(gts, preds, chartType)\n",
    "\n",
    "    P = computePrecision(gt_groups, pred_groups, thres=0.75)\n",
    "    R = computeRecall(gt_groups, pred_groups, thres=0.75)\n",
    "    \n",
    "    macro_P.append(P)\n",
    "    macro_R.append(R)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro_P: 0.5838068181818181  macro_R: 0.5011583011583012 F score: 0.5393346347992855\n"
     ]
    }
   ],
   "source": [
    "macro_P = np.array(macro_P)\n",
    "macro_R = np.array(macro_R)\n",
    "macro_P_avg = macro_P[~np.isnan(macro_P)].mean()\n",
    "macro_R_avg = macro_R[~np.isnan(macro_R)].mean()\n",
    "print('macro_P:', macro_P_avg, \" macro_R:\", macro_R_avg, 'F score:', (2*macro_P_avg*macro_R_avg) / (macro_P_avg + macro_R_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bar \n",
    "val:\n",
    "baseline-0.75: macro_P: 0.9636824998806985  macro_R: 0.9416431134713873 F score: 0.9525353390794559\n",
    "macro_P: 0.9266515397571432  macro_R: 0.8773809664720859 F score: 0.9013434300409017\n",
    "test:\n",
    "baseline-0.75:macro_P: 0.9629660516244063  macro_R: 0.9394488415246871 F score: 0.9510620894358737\n",
    "macro_P: 0.9253761688833957  macro_R: 0.8742844543781882 F score: 0.8991050739783865"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pie\n",
    "test:\n",
    "baseline-0.75: macro_P: 0.9919837846366353  macro_R: 0.939576581277725 F score: 0.965069225377917\n",
    "macro_P: 0.9786097545456947  macro_R: 0.8993714214010163 F score: 0.9373189222719189"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Line\n",
    "test:\n",
    "baseline-0.75: macro_P: 0.8901315373426927  macro_R: 0.8759199972596385 F score: 0.8829685866732011\n",
    "macro_P: 0.6254684531470246  macro_R: 0.5553709321566465 F score: 0.5883391122993549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChartReader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
